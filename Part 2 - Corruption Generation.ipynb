{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f69d28de-1552-4e74-bf33-0b2701283be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97870b5-0acf-4a5b-aba2-8af6a0656dd1",
   "metadata": {},
   "source": [
    "### Function to Corrupt Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ed97da-79e4-49aa-b9ea-1de5947ed258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_sentence(sentence, swap_probability=0.1):\n",
    "    punctuation = string.punctuation\n",
    "    punctuations_in_sentence = [ch for ch in sentence if ch in punctuation]\n",
    "    \n",
    "    if not punctuations_in_sentence:\n",
    "        return sentence\n",
    "\n",
    "    char_to_move = random.choice(punctuations_in_sentence)\n",
    "    sentence_without_char = sentence.replace(char_to_move, \"\", 1)\n",
    "    \n",
    "\n",
    "    words = sentence_without_char.split()\n",
    "    word_index = random.randint(0, len(words) - 1)\n",
    "    place_before = random.choice([True, False])\n",
    "    \n",
    "    if place_before:\n",
    "        corrupted_sentence = \" \".join(words[:word_index] + [char_to_move] + words[word_index:])\n",
    "    else:\n",
    "        corrupted_sentence = \" \".join(words[:word_index + 1] + [char_to_move] + words[word_index + 1:])\n",
    "    \n",
    "    if random.random() < swap_probability and len(words) > 1:\n",
    "        idx1, idx2 = random.sample(range(len(words)), 2)\n",
    "        words[idx1], words[idx2] = words[idx2], words[idx1]\n",
    "        corrupted_sentence = \" \".join(words)\n",
    "    \n",
    "    return corrupted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e933c87-51db-4af2-a2d7-e424a2c42088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hello, world! This is a test sentence.\n",
      "Corrupted: Hello, world This sentence. a test is\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hello, world! This is a test sentence.\"\n",
    "corrupted = corrupt_sentence(sentence)\n",
    "print(\"Original:\", sentence)\n",
    "print(\"Corrupted:\", corrupted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713d3ff0-7884-4749-84cb-9079782b96de",
   "metadata": {},
   "source": [
    "### Generating Corrupted Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d661b-4e72-4803-af56-f7d2fb3dffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_read(file_path):\n",
    "    valid_lines = []\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        for line in f:\n",
    "            if '\\ufffd' not in line:  # Check for replacement characters\n",
    "                valid_lines.append(line)\n",
    "    return valid_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729e192-0b53-47f8-8c40-ff2b31229825",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = safe_read(train_data_path)\n",
    "train_data_df = pd.DataFrame([line.strip().split('\\t') for line in lines], columns=['Sentence_A', 'Sentence_B'])\n",
    "train_data_df['labels'] = 0\n",
    "train_data_df = train_data_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e485286-a363-4b97-8d2e-df1b444a79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df[\"New Corrupted Sentence\"] = corrupt_sentence(train_data_df[\"Sentence_A\"])\n",
    "train_data_df[\"New Corrupted Sentence\"].to_csv(\"./part2.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fd3a15-0db2-4789-8ce8-5f408911462c",
   "metadata": {},
   "source": [
    "### Deep Learning approach\n",
    "Plan: \n",
    "- train an encoder-decoder model to learn embeddings of Sentence_B from the embeddings of Sentence_A.\n",
    "- Use this trained model to generate embeddings of corrupted sentences\n",
    "- Cobvert back these embeddings into a corrupted sentece.\n",
    "I explored this plan, but I could not decode the embeddings from my model into corrupted sentences. I will work on this for the next couple of days."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
